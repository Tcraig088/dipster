{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle \n",
    "import hyperspy.api as hs\n",
    "sys.path.append(\"..\")\n",
    "import tomondt\n",
    "from tomondt import Operator, Viewer, utils\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import sys\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from dipster.solver import Solver\n",
    "from dipster import alignments, tomo\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import scipy.io as io\n",
    "\n",
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "dip_path = os.path.join(path, 'Dipster-recs')\n",
    "vol_path = os.path.join(path, 'Volumes')\n",
    "ts_path = os.path.join(path, 'TiltSeries')\n",
    "rec_path = os.path.join(path, 'Reconstructions')\n",
    "data_path =  os.path.join(path, 'Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SIRT reconstruction for Data Set\n",
    "sample_name = 'Rod-0'\n",
    "descriptor = None\n",
    "folder = 'Static'\n",
    "frame = 100\n",
    "if descriptor is None:\n",
    "    ts_name = sample_name\n",
    "else:\n",
    "    ts_name = sample_name +'-'+ descriptor \n",
    "\n",
    "ts_file = os.path.join(ts_path, ts_name+'-ts.pkl')\n",
    "\n",
    "\n",
    "ts = pickle.load(open(ts_file, 'rb'))\n",
    "ts.data  = alignments.rebin(ts.data, 4)\n",
    "alg = lambda x: tomondt.algorithms.sirt(x,50)\n",
    "rec_file = os.path.join(rec_path, folder, ts_name+'.vmf')\n",
    "rec = tomondt.Operator('cupy',0).bp(rec_file,ts,alg,frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruct A series of Reconstructions with different window sizes\n",
    "sample_name = 'Cage-2'\n",
    "descriptor = 'w90'\n",
    "folder = 'Optimizations'\n",
    "\n",
    "\n",
    "start = 55 # default 5\n",
    "end = 65 # default 100\n",
    "increment  = 1 # default 5\n",
    "\n",
    "if descriptor is None:\n",
    "    ts_name = sample_name\n",
    "else:\n",
    "    ts_name = sample_name +'-'+ descriptor \n",
    "\n",
    "ts_file = os.path.join(ts_path, ts_name+'-ts.pkl')\n",
    "ts = pickle.load(open(ts_file, 'rb'))\n",
    "ts.data  = alignments.rebin(ts.data, 4)\n",
    "alg = lambda x: tomondt.algorithms.sirt(x,50)\n",
    "if not os.path.exists(os.path.join(rec_path, folder, ts_name)):\n",
    "    os.mkdir(os.path.join(rec_path, folder, ts_name))\n",
    "\n",
    "i=start\n",
    "while i<=100:\n",
    "    rec_file = os.path.join(rec_path, folder, ts_name, str(i)+'.vmf' )\n",
    "    rec = tomondt.Operator('cupy',0).bp(rec_file,ts,alg,i)\n",
    "    if i == end:\n",
    "        break\n",
    "    i += increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '\\\\\\\\ematbyname\\\\emat\\\\TimC\\\\DIPSTER-PublicationData\\\\Publication-Data\\\\Reconstructions\\\\Optimizations\\\\Cage-0-w90'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\Python\\dippy\\DIP-STER\\scripts\\measures.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/Python/dippy/DIP-STER/scripts/measures.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m opt_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rec_path, \u001b[39m'\u001b[39m\u001b[39mOptimizations\u001b[39m\u001b[39m'\u001b[39m, ts_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Python/dippy/DIP-STER/scripts/measures.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m vol \u001b[39m=\u001b[39m tomondt\u001b[39m.\u001b[39mload_vmf(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(vol_path, sample_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.vmf\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/Python/dippy/DIP-STER/scripts/measures.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(opt_folder)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Python/dippy/DIP-STER/scripts/measures.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(opt_folder)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/Python/dippy/DIP-STER/scripts/measures.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m read_files \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '\\\\\\\\ematbyname\\\\emat\\\\TimC\\\\DIPSTER-PublicationData\\\\Publication-Data\\\\Reconstructions\\\\Optimizations\\\\Cage-0-w90'"
     ]
    }
   ],
   "source": [
    "# Evaluates Optimization Frame Optimum \n",
    "sample_name = 'Cage-0'\n",
    "descriptor = 'w90'\n",
    "if descriptor is None:\n",
    "    ts_name = sample_name\n",
    "else:\n",
    "    ts_name = sample_name +'-'+ descriptor \n",
    "opt_folder = os.path.join(rec_path, 'Optimizations', ts_name)\n",
    "\n",
    "vol = tomondt.load_vmf(os.path.join(vol_path, sample_name+'.vmf'))\n",
    "x = np.zeros(len(os.listdir(opt_folder)))\n",
    "y = np.zeros(len(os.listdir(opt_folder)))\n",
    "read_files = 0\n",
    "for file in os.listdir(opt_folder):\n",
    "    frame = int(file.split('.')[0])\n",
    "    rec_file = os.path.join(opt_folder, file)\n",
    "    rec = tomondt.load_vmf(rec_file) \n",
    "    psnr_val = 0\n",
    "    for i in rec.times:\n",
    "        temp_array = i - vol.times\n",
    "        comp_index = np.argmin(abs(temp_array))\n",
    "        if isinstance(comp_index, Iterable):\n",
    "            vol_data = np.zeros_like(vol.read_record(comp_index[0],False))\n",
    "            for j in comp_index:\n",
    "                vol_data += vol.read_record(j,False)  \n",
    "            vol_data = vol_data/len(comp_index)\n",
    "        else:\n",
    "            vol_data = vol.read_record(comp_index,False)\n",
    "        vol_data = alignments.rebin(vol_data, 4, True)\n",
    "        rec_data = rec.read_record(i)\n",
    "        psnr_val += psnr(vol_data, rec_data, data_range=1.0)\n",
    "    psnr_val = psnr_val/len(rec.times)\n",
    "    x[read_files] = frame\n",
    "    y[read_files] = psnr_val\n",
    "    read_files += 1\n",
    "indices = np.argsort(x)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "data_file  = os.path.join(data_path, ts_name+'-optimization.mat')\n",
    "if os.path.exists(data_file):\n",
    "    os.remove(data_file)\n",
    "io.savemat(data_file, {\"frames\": x.T, \"psnr\": y.T})\n",
    "fig = px.line(x=x, y=y, title=\"Simple Line Plot\")\n",
    "fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Missing Wedge Contribution PSNR and SSIM for DataSet\n",
    "sample_name = 'Cage-0'\n",
    "descriptor = 'w90'\n",
    "voltype = 0 # 0 for SIRT 1 for DIPSTER\n",
    "folder = 'MissingWedge'\n",
    "slice_index = 64\n",
    "\n",
    "if descriptor is None:\n",
    "    ts_name = sample_name\n",
    "else:\n",
    "    ts_name = sample_name +'-'+ descriptor \n",
    "\n",
    "vol_file = os.path.join(vol_path, sample_name+'.vmf')\n",
    "vol = tomondt.load_vmf(vol_file)\n",
    "match voltype:\n",
    "    case 0:\n",
    "        suffix = '-sirt'\n",
    "        suffix_underscored = '_sirt'\n",
    "        rec_file = os.path.join(rec_path, folder, ts_name+'.vmf')\n",
    "    case 1:\n",
    "        suffix = '-dipster'\n",
    "        suffix_underscored = '_dipster'\n",
    "        for file in os.listdir(os.path.join(dip_path, folder)):\n",
    "            if ts_name in file:\n",
    "                rec_file = os.path.join(dip_path, folder, file)\n",
    "                break\n",
    "    case _:\n",
    "        raise ValueError('Invalid Volume Type')\n",
    "    \n",
    "    \n",
    "rec = tomondt.load_vmf(rec_file)\n",
    "\n",
    "ssims = np.zeros(len(rec.times))\n",
    "psnrs = np.zeros(len(rec.times))\n",
    "mwedge = np.zeros(len(rec.times))\n",
    "times = rec.times\n",
    "\n",
    "read_index  = 0\n",
    "for i in rec.times:\n",
    "    rec_data = rec.read_record(i)\n",
    "    temp_array = i - vol.times\n",
    "    comp_index = np.argmin(abs(temp_array))\n",
    "    if isinstance(comp_index, Iterable):\n",
    "        vol_data = np.zeros_like(vol.read_record(comp_index[0],False))\n",
    "        for j in comp_index:\n",
    "            vol_data += vol.read_record(j,False)  \n",
    "        vol_data = vol_data/len(comp_index)\n",
    "    else:\n",
    "        vol_data = vol.read_record(comp_index,False)\n",
    "    vol_data = alignments.rebin(vol_data, 4, True)   \n",
    "    ssims[read_index] = ssim(vol_data, rec_data, data_range=1.0)\n",
    "    psnrs[read_index] = psnr(vol_data, rec_data, data_range=1.0)\n",
    "    mw2 = psnr(vol_data[:,slice_index,:] , rec_data[:,slice_index,:], data_range=1.0)\n",
    "    mw1 = psnr(vol_data[:,:,slice_index], rec_data[:,:,slice_index], data_range=1.0)\n",
    "    mwedge[read_index] = (mw2/mw1)*100\n",
    "    read_index += 1\n",
    "\n",
    "\n",
    "data_file  = os.path.join(data_path, ts_name+suffix+'-true.mat')\n",
    "if os.path.exists(data_file):\n",
    "    os.remove(data_file)\n",
    "    \n",
    "data_dict = {}\n",
    "data_dict['times'] = times\n",
    "data_dict['psnr'] = psnrs\n",
    "data_dict['ssim'] = ssims\n",
    "data_dict['mwedge'] = mwedge\n",
    "data_dict['mwedge_average'] = np.mean(mwedge)\n",
    "data_dict['ssims_average'] = np.mean(ssims)\n",
    "data_dict['psnrs_average'] = np.mean(psnrs)\n",
    "data_struct = {}\n",
    "data_struct[ts_name.replace('-','_')+suffix_underscored] = data_dict\n",
    "io.savemat(data_file, data_struct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting data of DIPSTER reconstruction quality\n",
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Dipster-recs'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\volumes'\n",
    "\n",
    "sample_name = 'Cube-0'\n",
    "\n",
    "df = pd.DataFrame(columns=['ssim', 'psnr'])\n",
    "ref_name = os.path.join(vol_path, sample_name+'.vmf')\n",
    "for structure in os.listdir(rec_path):\n",
    "    if (sample_name  in structure):\n",
    "        df = pd.DataFrame(columns=['ssim', 'psnr'])\n",
    "        rec_name = os.path.join(rec_path, structure)\n",
    "        rec = tomondt.load_vmf(rec_name)\n",
    "        ref = tomondt.load_vmf(ref_name)\n",
    "        for i in rec.times:\n",
    "            ref_data = ref.read_record(i)\n",
    "            ref_data = alignments.rebin(ref_data, 4, True)\n",
    "            rec_data = rec.read_record(i)\n",
    "            data_row = {'ssim': ssim(ref_data, rec_data, data_range=1.0), 'psnr': psnr(ref_data, rec_data, data_range=1.0)} \n",
    "            df = pd.concat([df, pd.DataFrame([data_row])], ignore_index=True)\n",
    "        df.to_csv(os.path.join(path, sample_name+'dipster.csv'))\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Where the data is stored\n",
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "ts_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\TiltSeries'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Reconstructions'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\volumes'\n",
    "\n",
    "\n",
    "\n",
    "for item in os.listdir(ts_path):\n",
    "    ts_name = os.path.join(ts_path, item)\n",
    "    ts = pickle.load(open(ts_name, 'rb'))\n",
    "    ts.data  = alignments.rebin(ts.data, 4)\n",
    "    for ref_item in os.listdir(vol_path):\n",
    "       sample_name = ref_item.split('.')[0]\n",
    "       if sample_name in ts_name and 'Rod' in sample_name:\n",
    "           df = pd.DataFrame(columns=['psnr', 'framesize'])\n",
    "           for i in range(100):\n",
    "               if (i % 2 != 0 and i > 10) or i == 100:\n",
    "                    alg = lambda x: tomondt.algorithms.sirt(x,50)\n",
    "                    fname = os.path.join(rec_path, sample_name+'_'+str(i)+'.vmf')\n",
    "                    rec = tomondt.Operator('cupy',0).bp(fname,ts,alg,i)\n",
    "                    rec = tomondt.load_vmf(fname)\n",
    "                    ref = tomondt.load_vmf(os.path.join(vol_path,ref_item))\n",
    "                    psnr_val = 0 \n",
    "                    n = 0\n",
    "                    for j in range(len(rec.times)):\n",
    "                        for k in range(len(ref.times)):\n",
    "                            if rec.times[j] == ref.times[k]:\n",
    "                                rec_data = rec.read_record(rec.times[j])\n",
    "                                ref_data = ref.read_record(ref.times[k])\n",
    "                                ref_data = alignments.rebin(ref_data, 4, True)\n",
    "                                psnr_val += psnr(ref_data, rec_data, data_range=1.0)\n",
    "                                n += 1\n",
    "                    data_row = {'psnr': psnr_val/n, 'framesize': i} \n",
    "                    df = pd.concat([df, pd.DataFrame([data_row])], ignore_index=True)\n",
    "                    df.to_csv(os.path.join(path, sample_name+'_optimizing_sirt_psnr.csv'))\n",
    "                    print(sample_name, i, psnr_val/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "ts_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\TiltSeries'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Reconstructions'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Volumes'\n",
    "\n",
    "ref_name = os.path.join(vol_path, 'Rod-0.vmf') \n",
    "rec_name = os.path.join(rec_path, 'Rod-0_99.vmf')\n",
    "ref = tomondt.load_vmf(ref_name)\n",
    "rec = tomondt.load_vmf(rec_name)\n",
    "df = pd.DataFrame(columns=['index','ssim', 'psnr'])\n",
    "for i in range(len(ref.times)):\n",
    "    for j in range(len(rec.times)):\n",
    "        if ref.times[i]==rec.times[j]:\n",
    "            ref_data = ref.read_record(ref.times[i])\n",
    "            ref_data = alignments.rebin(ref_data, 4, True)\n",
    "            rec_data = rec.read_record(rec.times[j])\n",
    "            data_row = {'index': i, 'ssim': ssim(ref_data, rec_data, data_range=1.0), 'psnr': psnr(ref_data, rec_data, data_range=1.0)} \n",
    "            print(data_row)\n",
    "            df = pd.concat([df, pd.DataFrame([data_row])], ignore_index=True)\n",
    "df.to_csv(os.path.join(path, 'Op-Rod_0.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "ts_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\TiltSeries'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Reconstructions'\n",
    "dip_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Dipster-recs'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Volumes'\n",
    "\n",
    "sample_name = 'Rod-0'\n",
    "id = '99'\n",
    "axis = 2\n",
    "sliceid = 64\n",
    "ref = tomondt.load_vmf(os.path.join(vol_path, sample_name+'.vmf'))\n",
    "for item in os.listdir(dip_path):\n",
    "    if sample_name in item:\n",
    "        dip = tomondt.load_vmf(os.path.join(dip_path, item))\n",
    "for item in os.listdir(rec_path):\n",
    "    if sample_name in item and id in item:\n",
    "        rec = tomondt.load_vmf(os.path.join(rec_path, item))\n",
    "\n",
    "ref_image = ref.read_record(ref.times[0])\n",
    "ref_image = alignments.rebin(ref_image, 4, True)       \n",
    "dip_image = dip.read_record(dip.times[0])\n",
    "rec_image = rec.read_record(rec.times[0])\n",
    "if axis == 0:\n",
    "    ref_image = ref_image[sliceid,:,:]\n",
    "    rec_image = rec_image[sliceid,:,:]\n",
    "    dip_image = dip_image[sliceid,:,:]\n",
    "elif axis == 1:\n",
    "    ref_image = ref_image[:,sliceid,:]\n",
    "    rec_image = rec_image[:,sliceid,:]\n",
    "    dip_image = dip_image[:,sliceid,:]\n",
    "else: \n",
    "    ref_image = ref_image[:,:,sliceid]\n",
    "    rec_image = rec_image[:,:,sliceid]\n",
    "    dip_image = dip_image[:,:,sliceid]\n",
    "    \n",
    "psnr_rec = psnr(ref_image, rec_image, data_range=1.0)\n",
    "psnr_dip = psnr(ref_image, dip_image, data_range=1.0)\n",
    "ssim_rec = ssim(ref_image, rec_image, data_range=1.0)\n",
    "ssim_dip = ssim(ref_image, dip_image, data_range=1.0)\n",
    "print(psnr_rec, psnr_dip, ssim_rec, ssim_dip)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For measuring Missing Wedge Artefacts\n",
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "ts_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\TiltSeries'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Reconstructions'\n",
    "dip_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Dipster-recs'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Volumes'\n",
    "\n",
    "sample_name = 'Rod-0'\n",
    "angles = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "for sample in os.listdir(vol_path):\n",
    "    if sample_name in sample:\n",
    "        ref = tomondt.load_vmf(os.path.join(vol_path, sample))\n",
    "for ts in os.listdir(ts_path):\n",
    "    for i in angles:\n",
    "        if sample_name in ts and str(i) in ts:\n",
    "            tilt_series = pickle.load(open(os.path.join(ts_path, ts), 'rb'))\n",
    "            rec_name = sample_name+'_'+str(i)+'.vmf'\n",
    "            rec = tomondt.load_vmf(os.path.join(rec_path, rec_name))\n",
    "            for t in ref.times:\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For measuring Noise Artefacts\n",
    "path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data'\n",
    "ts_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\TiltSeries'\n",
    "rec_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Reconstructions'\n",
    "dip_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Dipster-recs'\n",
    "vol_path = r'\\\\ematbyname\\emat\\TimC\\DIPSTER-PublicationData\\Publication-Data\\Volumes'\n",
    "\n",
    "sample_name = 'Cage-2'\n",
    "values = [4]\n",
    "df = pd.DataFrame(columns=['ssim', 'psnr'])\n",
    "viewer = tomondt.Viewer()\n",
    "for sample in os.listdir(vol_path):\n",
    "    if sample_name in sample:\n",
    "        ref = tomondt.load_vmf(os.path.join(vol_path, sample))\n",
    "for ts in os.listdir(ts_path):\n",
    "    for i in values:\n",
    "        if sample_name in ts and ('n'+str(i)) in ts:\n",
    "            tilt_series = pickle.load(open(os.path.join(ts_path, ts), 'rb'))\n",
    "            tilt_series.data = alignments.rebin(tilt_series.data, 4).astype('float32')\n",
    "            rec_name = sample_name+'_n'+str(i)+'.vmf'\n",
    "            rec = tomondt.Operator('cupy',0).bp(os.path.join(rec_path, rec_name), tilt_series, lambda x: tomondt.algorithms.sirt(x,50), 100)\n",
    "            ref_data,rec_data = alignments.rebin(ref.read_record(ref.times[0]),4,True), rec.read_record(rec.times[0])\n",
    "            #rec_data = (rec_data - np.min(rec_data))/(np.max(rec_data)-np.min(rec_data))\n",
    "            viewer.add_image(rec_data, name=rec_name)\n",
    "            data_row = {'index': i, 'ssim': ssim(ref_data, rec_data, data_range=1.0), 'psnr': psnr(ref_data, rec_data, data_range=1.0)} \n",
    "            print(i, data_row)\n",
    "            df = pd.concat([df, pd.DataFrame([data_row])], ignore_index=True)\n",
    "df.to_csv(os.path.join(path, 'Noise-Cage_0.csv'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
